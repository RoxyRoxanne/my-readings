
    siraj raval
      The Math of Intelligence
        ref
          http://localhost:8888/notebooks/Course-Math_of_Intelligence-Siraj_Raval.ipynb
        Gradient Descent
        Support Vector Machines
          http://localhost:8888/notebooks/study_jupyter.ipynb
    Deep Learning - Coursera Andrew Ng 
      welcome
        what you'll learn
          courses
            1. neural networks and deep learning
            2. practical aspects of deep learning
            3. structuring ml project
              train/dev/test sets have changed
              they might come from different distributions
              end to end dl
                when you should use it
            4. convolutional neural networks: cnn
              applied to images
            5. natural language processing: sequence models
              rnn, lstm
      introduction to dl
        what is a neural network?
          housing price prediction  
            x: size of house
            y: price
            y = f(x)
            linear regression: straight line fitting
            Size x -> neuron (node) -> price y
              neuron is a function
            ReLU function: zero then linear
            slide2
              /Users/mertnuhoglu/Dropbox/public/img/ss-209.png
              size, # bedrooms -> o -> family size
              zip code -> o -> walkability
              zip code + wealth -> o -> school quality
              family size + walkability + school quality -> o -> price
              x: size, #bedrooms, zip code, wealth
              y: price
              each node takes all 4 features as input
              /Users/mertnuhoglu/Dropbox/public/img/ss-210.png
              input layer
              density connector: nodes in the middle
              given enough data (x,y), dl are accurate in estimating functions to map x to y
        supervised learning with neural networks
          input x
          output y
          ex: 
            input: home features
            output: price
            application: real estate
            input: ad, user info
            output: click on ad? (0/1)
            application: online advertising
            input: image
            output: object (1,...1000)
            application: photo tagging
            audio | text transcript | speech recognition
            english | output | translation
            image info | position of other cars | autonomous driving
          different architectures of nn
            real estate, online advertising -> standard nn
            photo tagging -> cnn
            speech recognition, translation -> rnn
            autonomous driving -> custom/hybrid nn
          nn examples
            standard nn
            convolutional nn
            recurrent nn: for sequential data
          data types
            structured data
              databases: relational, hierarchical
            unstructured data
              raw audio, image, text
        why is deep learning taking off
          scale drives deep learning progress
            /Users/mertnuhoglu/Dropbox/public/img/ss-211.png
            amount of data vs performance
            traditional learning algorithms (SVM, logit)
              improves for a while, but after a while performance stays stable
            small nn
              performance improves a little better for large data
            data: labeled data
            amount of data: m
          innovations in
            data
            computation 
            algorithms
              to make algorithms run faster
                ex: activation function: sigmoid function to RElu function
                  makes gradient descent run faster
          iterative process
            idea -> code -> experiment -> idea
              feedback cycle: training and experimenting
              fast computation improves feedbacks
        about this course
          courses
        course resources
          discussion forum 
